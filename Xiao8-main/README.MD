<div align="center">

![小八Logo](assets/xiaoba_logo.jpg)

[English Version](docs/README_en.md)
# <s>小八</s> Lanlan :kissing_cat: <br>一个语音原生的全场景AI伙伴

**新手友好、开箱即用，无需显卡的全场景AI <small><s>猫娘</s></small> 伙伴**

[![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Commit](https://img.shields.io/github/last-commit/wehos/Xiao8?color=green)]()
[![百度云](https://custom-icon-badges.demolab.com/badge/百度云-Link-4169E1?style=flat&logo=baidunetdisk)](https://pan.baidu.com/s/1qb9XVV94c2FwhIeQO2De5A?pwd=kuro)
[![QQ群](https://custom-icon-badges.demolab.com/badge/QQ群-1048307485-00BFFF?style=flat&logo=tencent-qq)](https://qm.qq.com/q/mxDoz0TnGg)

**:older_woman: 我奶奶都能在3分钟内配置好的赛博猫娘！**

*Don't ask me anything. Ask 兰兰！*

</div>

<div align="center">

#### 功能演示（完整版见B站） [![Bilibili](https://img.shields.io/badge/Bilibili-%E6%95%99%E7%A8%8B%E8%A7%86%E9%A2%91-blue)](https://www.bilibili.com/video/BV1mM32zXE46/)

https://github.com/user-attachments/assets/9d9e01af-e2cc-46aa-add7-8eb1803f061c

</div>

---

# 项目简介
Lanlan（兰兰）是一个新手友好、开箱即用的，具有听觉、视觉、工具调用和多端同步功能的AI~~猫娘~~伙伴。本项目有三个核心目标：

1. **极致的低延迟**。本项目的用户界面以语音交互为主，一切系统级设计皆须优先确保**降低语音延迟**，且任何服务不得阻塞对话进程。

1. **全场景同步**。猫娘可以在手机、电脑和智能眼镜上同时存在，且**同一只猫娘**在不同终端同时存在时，**行为应当完全同步**。 (假想场景：如果家中有多个显示器，每一个显示器上都放置着猫娘，那么我们希望无论走到哪里都是在跟同一只猫娘对话，实现全方位环绕式体验。)

1. **轻量化**。每一项技术的引入都必须提升实际的用户体验，避免增加不必要的插件和选项。

### 技术路线

后端以Python为主，以实时多模态API为主要处理器，搭配多个基于文本的插件模组。前端以H5+JS为主，通过Electron和PWA转换为App。

# 快速开始

1. **获取阿里云API**。在阿里云的百炼平台[官网](https://bailian.console.aliyun.com/)注册账号。新用户实名认证后可以获取大量免费额度，记得留意页面上的"新人福利"广告。注册完成后，请访问[控制台](https://bailian.console.aliyun.com/api-key?tab=model#/api-key)获取API Key。*一键包用户*可以通过设置页里的按钮设置API Key，*开发者*也可以直接修改`config/api.py`里的内容（首次配置请参考`config/api_template.py`）。
   > *注：本项目提供的都是官方链接，不含任何推广，本人无法从中获取任何收益。阿里的官网目前做的很烂，请忍耐orz*

1. **体验网页版**。对于*一键包用户*，直接运行`启动网页版.bat`即可打开网页版。**请耐心等待网页刷新，并先根据提示配置API Key**。

1. **体验桌宠模式**。如果网页版可以正常使用，*一键包用户*可以考虑继续通过`启动App版.bat`开启桌宠模式。注意，**请不要同时使用网页版和App版。请确认exe文件没有被系统或杀毒软件隔离。** *使用结束后请在桌面右下角找到小八图标，右键退出，并手动关闭终端。*

>  *对于**开发者**，请在克隆本项目后，(1)新建pyhon3.12环境。(2)执行`pip install -r requirements.txt`安装依赖。(3)复制`config/api_template.py`到`config/api.py`并进行必要配置。(4)执行`python memory_server.py`和`python main_server.py`。(5)通过main server中指定的端口（默认为`http://localhost:48911`）访问网页版。*

# 进阶内容

## 修改人设

- 网页版访问`http://localhost:48911/chara_manager`即可进入人设编辑页面。初始 ~~猫娘~~ 伙伴的预设名称为`小天`，建议直接修改名字，并一项一项添加或修改基础人设，但尽量控制数量。

- 进阶人设主要包括**Live2D模型设置(live2d)**和**声音设置(voice_id)**。如果你想要更改**Live2D模型**，请先将模型目录复制到本项目中的`static`文件夹下。从进阶设置中可以进入Live2D模型管理界面，可以更换模型，并通过拖拽和鼠标滚轮调整模型的位置和大小。如果你想要更改**角色声音**，请准备一段15秒左右的连贯、干净的语音录音。通过进阶设置进入语音设置页面，上传录音即可完成自定义语音。

- 进阶人设中还有一个`system_prompt`，可以对系统指令进行完全自定义，但不建议修改。

## 修改API提供商

- 通过访问`http://localhost:48911/api_key`可以切换核心API和辅助API（记忆/语音）的服务提供商。Qwen功能全面，GLM完全免费。

## 记忆审阅

- 通过访问`http://localhost:48911/memory_browser`可以浏览和校对近期记忆与摘要，一定程度上缓解模型复读、认知错误等问题。

## 参与开发

本项目环境依赖非常简单，请在`python3.12`环境中执行`pip install -r requirements.txt`即可。请注意将`config/api_template.py`复制为`config/api.py`.开发者建议加入企鹅群1048307485，猫娘名称见项目标题。

# TODO List（开发计划）

## A. 高优先级

1. 兼容工具调用或MCP（本质是工具调用，不强求兼容MCP）。

1. 用React对前端进行重构，筹备手机端独立运行版本。（后续可能会将后端逻辑同样改写为到React，形成一个独立Repo。）

## B. 中等优先级

1. 通过引入Unity支持3D模型。

1. 猫娘网络。允许猫娘之间自行通信。需要一定的用户量基础，因此优先级下调。

1. 将Memory Server改造成MCP服务器，以MCP的形式让同一个猫娘兼容不同语言模型、聊天框架。（工作量不是很大）

1. 接入QQ/cursor等外部软件。由于语音模型是实时特化的，cursor类软件只能以工具形式被Lanlan调用；QQ类软件只能将Memory Server嵌入到其他框架。

# Q&A

> *你为什么要用阿里？为什么不用Deepseek？*

因为阿里是全模态模型，它说话快。

> *你为什么要用8B模型？你不知道8B模型都是笨比吗？*

因为阿里目前只有8B模型，它说话快。

> *能不能换别的厂家/离线运行/换别的模型/xxx试试？*

对不起，但是它说话快。

> *为什么我的AI感觉笨笨的？*

本项目无法对AI的**智能水平**负责，只能帮助您选择当前综合性能最优的解决方案。如果您已经看过本项目在Bilibili的视频，那么直播版与开源版代码逻辑一致，只有支持的API接口不一致。有条件者可以将`config/api.py`中的`CORE_URL`/`CORE_API_KEY`/`CORE_MODEL`替换成OpenAI的`GPT-4o`版本，即可将模型从Qwen升级为`GPT-4o`。也可以**等待阿里或其他国内厂家的升级与跟进**。

**技术的进步不在一朝一夕，请耐心守候AI的成长**！

> *Live2D模型的嘴巴怎么张不开？*

本项目已经兼容了L2D模型的全部两种口型同步方式。口型同步出现问题，大概率是Live2D模型本身不支持，而不是本项目的问题。

> *是否支持MCP服务、工具、插件？*

OpenAI官方的Realtime API支持`tool calling`功能，因此，本项目与MCP服务兼容，且直播版已经实装了联网搜索等工具。但是，与常规文本模型不同的是，实时模型使用工具需要考虑异步协同和阻塞问题。此外，目前阿里平台并不支持工具调用。因此，开源项目暂时没有MCP兼容性的计划，留待国内厂商实现相关接口后再跟进。

> *本项目支持哪些语言模型？*

本项目依赖于实时全模态API。直播版本使用的是Gemini Live API，开源版本使用的是[OpenAI Realtime API](https://platform.openai.com/docs/guides/realtime)。Gemini Live接口具有更好的效果，但目前**只支持谷歌**。OpenAI Realtime接口规范目前**有OpenAI，阿里云，智谱 三家服务商**支持，未来可能兼容更多模型。开源版支持`Qwen-Omni-Realtime`,`GLM-Realtime`和`GPT-4o-Realtime`三个模型。

**已知其他支持实时模式但不兼容OpenAI Realtime的模型：**(字节跳动)豆包实时语音交互，(商汤)SenseNova V6 Omni，(科大讯飞)星火认知超拟人

> *为什么xxx项目的语音对话延迟比你还低？*

影响对话延迟的因素有：
- ***上下文长度***：主要因素。冗长的人设文本和记忆池，会导致对话延迟的显著上升。
- ***模型大小***：主要因素。越大的模型越智能，需要在智能与延迟之间权衡。本项目使用的模型中，`Qwen-Omni`是目前`8B`级别模型中最强的，`GPT-4o`则有`30B`级别的激活参数。小于8B的模型可能取得更低的响应延迟，但也会相应地变笨。注意，影响延迟的只有MoE中的激活参数量。
- ***缓存命中率***：当输入的前缀不变时，能够有效命中语言模型的KV缓存，从而显著降低延迟。因此，尽量使用增量式插入，而不要频繁修改先前（尤其是开头）的对话。
- *网络延迟*：通常在200ms以内，并不是影响*延迟*的主要因素。但如果存在网络波动，可能会导致语音*卡顿*。

如果你确实有发现相同上下文长度、相同智能水平下，延迟更低的解决方案，请提交issue，感谢分享。

> *你这项目的标题到底是个什么玩意儿？*

Chat酱是本人2023年3月制作的基于Chatgpt的QQ聊天猫娘。兰兰是2024年3月制作的基于GPT4v和Discord的语音+视觉多模态AI猫娘。小八是本人于2025年4月制作的全场景AI猫娘。标题承载了本人三年间的心路历程。现在姑且还是叫Project Lanlan吧？

> *为什么要设计xxx/xxx/xxx？*

建议进群私聊。很多目前看来冗余的设计，在直播版本（前瞻版本）中都有更多用处。

# 特别鸣谢

特别感谢*明天好像没什么*、*喵*和*小韭菜饺*协助测试。特别感谢*大毛怪灬嘎*提供的logo素材。
